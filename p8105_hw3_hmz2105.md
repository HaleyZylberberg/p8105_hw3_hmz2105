p8105_hw3_hmz2105
================
Haley Zylberberg

``` r
library (tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

## Problem 1

This problem uses data from “The Instacart Online Grocery Shopping
Dataset 2017” which is an anonymized dataset with over 3 million online
grocery orders from more than 200,000 Instacart users.

``` r
library(p8105.datasets)
data("instacart")
```

## Problem 2

This problem uses data from the Behavioral Risk Factors Surveillance
System for Selected Metropolitan Area Risk Trends (SMART) for 2002-2010.

First we call in the dataset.

``` r
library (p8105.datasets)
brfss_smart2010 
```

    ## # A tibble: 134,203 × 23
    ##     Year Locationabbr Locationdesc     Class Topic Question Response Sample_Size
    ##    <int> <chr>        <chr>            <chr> <chr> <chr>    <chr>          <int>
    ##  1  2010 AL           AL - Jefferson … Heal… Over… How is … Excelle…          94
    ##  2  2010 AL           AL - Jefferson … Heal… Over… How is … Very go…         148
    ##  3  2010 AL           AL - Jefferson … Heal… Over… How is … Good             208
    ##  4  2010 AL           AL - Jefferson … Heal… Over… How is … Fair             107
    ##  5  2010 AL           AL - Jefferson … Heal… Over… How is … Poor              45
    ##  6  2010 AL           AL - Jefferson … Heal… Fair… Health … Good or…         450
    ##  7  2010 AL           AL - Jefferson … Heal… Fair… Health … Fair or…         152
    ##  8  2010 AL           AL - Jefferson … Heal… Heal… Do you … Yes              524
    ##  9  2010 AL           AL - Jefferson … Heal… Heal… Do you … No                77
    ## 10  2010 AL           AL - Jefferson … Heal… Unde… Adults … Yes              316
    ## # ℹ 134,193 more rows
    ## # ℹ 15 more variables: Data_value <dbl>, Confidence_limit_Low <dbl>,
    ## #   Confidence_limit_High <dbl>, Display_order <int>, Data_value_unit <chr>,
    ## #   Data_value_type <chr>, Data_Value_Footnote_Symbol <chr>,
    ## #   Data_Value_Footnote <chr>, DataSource <chr>, ClassId <chr>, TopicId <chr>,
    ## #   LocationID <chr>, QuestionID <chr>, RESPID <chr>, GeoLocation <chr>

The problem will focus on the response to the question, what is “your
general health,” which is referred to as overall health, and which has
responses ordered from fair to excellent. I will re-format the dataset
to use appropriate variable names, and limit it to the overall health
topic. Next I will organize the responses as a factor taking levels
ordered from “Poor” to “Excellent.”

``` r
brfss_smart2010_df =
janitor::clean_names(brfss_smart2010)|>
  filter(topic == "Overall Health") |>
  rename(overall_health = response,
         state = locationabbr,
        county =  locationdesc,
        proportion_responded = data_value) |>
  mutate(overall_health = forcats::fct_relevel(overall_health, c("Poor", "Fair", "Good", "Very good", "Excellent"))) |>
    mutate(county = gsub("County", "", county)) |>
    mutate(county = gsub(".*-", "",county)) |>
  select(year, state, county, overall_health, sample_size, proportion_responded, confidence_limit_low, confidence_limit_high)
```

- Next we will answer which states were observed at 7 or more locations
  in 2002 and 2010.

  - These are the states with 7 or more observations in 2002:

``` r
brfss_smart2010_df |>
  filter(year == 2002) |>
  distinct(state, year, county) |>
  group_by(state) |> 
  summarize(locations = n()) |>
  filter(locations >= 7) |>
  knitr::kable()
```

| state | locations |
|:------|----------:|
| CT    |         7 |
| FL    |         7 |
| MA    |         8 |
| NC    |         7 |
| NJ    |         8 |
| PA    |        10 |

There are 6 states with 7 or more locations, with NJ having 8 and PA
having 10.

- These are the states with 7 or more observations in 2010:

``` r
brfss_smart2010_df |>
  filter(year == 2010) |>
  distinct(state, year, county) |>
  group_by(state) |> 
  summarize(locations = n()) |>
  filter(locations >= 7) |>
  knitr::kable()
```

| state | locations |
|:------|----------:|
| CA    |        12 |
| CO    |         7 |
| FL    |        41 |
| MA    |         9 |
| MD    |        12 |
| NC    |        12 |
| NE    |        10 |
| NJ    |        19 |
| NY    |         9 |
| OH    |         8 |
| PA    |         7 |
| SC    |         7 |
| TX    |        16 |
| WA    |        10 |

There are 14 states with 7 or more locations, which is higher than what
was recorded in 2002. Florida had the most locations at 41.

- Next, construct a dataset that is limited to Excellent responses, and
  contains year, state, and a variable that averages the data_value
  across locations within a state. And then output a “spaghetti” plot of
  this average value over time within a state.

``` r
excellent_brfss_smart2010_df =
  brfss_smart2010_df |>
  filter(overall_health == "Excellent") |>
  group_by(year, state) |>
  summarize (mean_proportion_responded = mean(proportion_responded)) |>
  select (year, state, mean_proportion_responded) 
```

    ## `summarise()` has grouped output by 'year'. You can override using the
    ## `.groups` argument.

``` r
excellent_brfss_smart2010_df |>
  ggplot( aes(x = year, y = mean_proportion_responded)) +
   geom_line(aes(group=state)) + geom_smooth() +
  theme(legend.position = "bottom")+
  labs(title = "Mean Proportion Who Responded Excellent to Overall 
  Health Question by State 
       Over Time",
    x = "Year",  
          y = "Mean Proportion Responded Excellent") 
```

    ## `geom_smooth()` using method = 'loess' and formula = 'y ~ x'

    ## Warning: Removed 4 rows containing non-finite values (`stat_smooth()`).

    ## Warning: Removed 3 rows containing missing values (`geom_line()`).

<img src="p8105_hw3_hmz2105_files/figure-gfm/excellent observations dataset-1.png" width="90%" />

This plot shows that from years 2002 through 2010 (which is the duration
of the data) the mean proportion of participants who responded
“excellent” to the question ” How is your overall health” was less than
30 for every state. It seems that the most states have an “excellent”
response of about 0.22%. Overall there appears to be a decreasing trend
for the “excellent” response over time.

- Next, make a two-panel plot showing, for the years 2006, and 2010, the
  distribution of data_value for responses (“Poor” to “Excellent”) among
  locations in NY State.

``` r
brfss_smart2010_df|>
  filter(state == "NY", year == "2006" | year == "2010") |>
  ggplot(aes(x = county, y=proportion_responded, fill = overall_health)) +
  geom_bar(stat="identity") +
  facet_grid(~year)+
  viridis::scale_fill_viridis(
    name = "county", 
    discrete = TRUE) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position = "bottom") +
  labs(title = "Proportion Responded to Overall Health Question 
Among Counties in NY For the Years 
2006 and 2010",
    x = "County",  
          y = "Proportion Responded") 
```

<img src="p8105_hw3_hmz2105_files/figure-gfm/plot of proportion responded in NY state by year-1.png" width="90%" />

This plot shows that among counties in NY, the proportion that responded
“Excellent” to the question “How is your overall health” was less than
37.5. Majority of responses in each county for both 2006 and 2010 was in
the very good range. It appears that the overall proportion of responses
did not change much per county from 2006 to 2010 except that the
counties Bronx, Erie, and Monroe were not included in 2006.

## Problem 3

This problem includes data from NHANES regarding participant demographic
information and accelerometer data.

Import demographic data. Skip first 4 rows as they are notes. Remove
participants younger than 21 and those with missing data. Recode sex as
1= male and 2= female and education as 1=less than high school, 2= high
school, 3=more than high school. Next convert education to a factor.

``` r
Demographic_df = 
  read_csv("data/nhanes_covar.csv", skip = 4) |> 
  janitor::clean_names()|>
  filter(age > 21) |>
  drop_na() |>
  mutate(
 sex = case_match(
    sex, 2~ 'female', 1 ~ 'male'),
 education = case_match(
   education, 1 ~ "less than high school", 2 ~ "high school", 3~ "more than high school")) |> mutate (education = as.factor(education))
```

    ## Rows: 250 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (5): SEQN, sex, age, BMI, education
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Next, import and tidy accelerometer data. As part of tidying will pivot
longer.

``` r
accel_df = 
  read_csv("data/nhanes_accel.csv")|> 
  janitor::clean_names() |>
   pivot_longer(
    min1:min1440,
    names_to = "minute",
    names_prefix = "min",
    values_to = "minute_value"
  ) |>
     mutate(minute = as.numeric(minute))
```

    ## Rows: 250 Columns: 1441
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (1441): SEQN, min1, min2, min3, min4, min5, min6, min7, min8, min9, min1...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Merge datasets.

``` r
MIMS_df = 
  inner_join(Demographic_df, accel_df, by="seqn")
```

Next determine the number of men and women in each education level.
Represent this data in both table and visual format.

``` r
MIMS_df |> 
  pivot_wider(
    names_from = minute,
    values_from = minute_value
  ) |>
  group_by(sex, education) |> 
  janitor::tabyl(sex, education) |> 
  knitr::kable(digits = 2)
```

| sex    | high school | less than high school | more than high school |
|:-------|------------:|----------------------:|----------------------:|
| female |          23 |                    28 |                    59 |
| male   |          34 |                    27 |                    54 |

``` r
MIMS_df |> 
  pivot_wider(
    names_from = minute,
    values_from = minute_value
  ) |>
ggplot(aes(x = education, fill = sex)) +
  geom_bar(position = "dodge") +
  labs(title = "Count of Men and Women by Education Level",
       x = "Education Level",
       y = "Count") +
  viridis::scale_fill_viridis(
    name = "Education", 
    discrete = TRUE) + 
  theme_minimal() + 
  theme(legend.position = "bottom")
```

<img src="p8105_hw3_hmz2105_files/figure-gfm/calculate number of men and women per education level-1.png" width="90%" />

Majority of men and women in this dataset have more than a high school
degree (n=59 for women and n=54 for men). More men had less than a high
school degree than women (34 vs 23).

Next aggregate accelerometer data for each participant and create a
variable called total_activity. Next create a scatter plot of total
activity for each participant by age, and compare males to females and
also group by education.

``` r
MIMS_df |> 
  group_by(seqn) |>
 mutate(total_activity = sum(minute_value)) |>
    mutate(education = forcats::fct_relevel(education, c("less than high school", "high school", "more than high school"))) |> 
  ggplot(aes(x = age, y = total_activity, color = sex)) +
    geom_point() +
  geom_smooth() + 
    facet_grid(~education) +
  theme(legend.position = "bottom")+
  labs(title = "Total Daily Accelerometer Value by Age in Males 
  Compared to Females, Grouped by 
  Education Level",
    x = "Age",  
          y = "Total Daily Accelerometer Data") 
```

    ## `geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = "cs")'

<img src="p8105_hw3_hmz2105_files/figure-gfm/aggregate accelerometer data for each participant and plot-1.png" width="90%" />

Next aggregate accelerometer data by minute to create a variable of mean
activity. Then create a scatter plot of mean activity per minute of the
day comparing males to females and grouped by education.

``` r
MIMS_df|>
  group_by(minute, sex, education) |>
  summarize(mean_activity = mean(minute_value, na.rm = TRUE)) |>
   mutate(education = forcats::fct_relevel(education, c("less than high school", "high school", "more than high school"))) |>
  ggplot(aes(x = minute, y = mean_activity, color = sex)) +
    geom_point() + geom_smooth() + 
    facet_grid(~education) +
  theme(legend.position = "bottom") +
  labs(title = "Mean Accelerometer Value Per Minute in Males 
  Compared to Females, Grouped by Education Level",
    x = "Minute",  
          y = "Mean Accelerometer Value")
```

    ## `summarise()` has grouped output by 'minute', 'sex'. You can override using the
    ## `.groups` argument.
    ## `geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = "cs")'

<img src="p8105_hw3_hmz2105_files/figure-gfm/aggregate accelerometer data by minute-1.png" width="90%" />
